{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56addb3",
   "metadata": {
    "id": "c56addb3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer,InputSpec\n",
    "import keras.layers as kl\n",
    "from glob import glob\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras import callbacks \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from  matplotlib import pyplot as plt\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import concatenate,Dense, Conv2D, MaxPooling2D, Flatten,Input,Activation,add,AveragePooling2D,BatchNormalization,Dropout\n",
    "%matplotlib inline\n",
    "import shutil\n",
    "from sklearn.metrics import  precision_score, recall_score, accuracy_score,classification_report ,confusion_matrix\n",
    "from tensorflow.python.platform import build_info as tf_build_info\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4506b2a",
   "metadata": {
    "id": "c4506b2a",
    "outputId": "a1a1cf80-ed37-4e25-9add-971310d73e90"
   },
   "outputs": [],
   "source": [
    "data_pd = pd.read_csv(r'C:\\Users\\divya\\Downloads\\archive\\HAM10000_metadata.csv')\n",
    "data_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c439a34b",
   "metadata": {
    "id": "c439a34b"
   },
   "outputs": [],
   "source": [
    "train_dir = os.path.join('HAM10000', 'train_dir')\n",
    "test_dir = os.path.join('HAM10000', 'test_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcce30f0",
   "metadata": {
    "id": "dcce30f0",
    "outputId": "1aeddd29-fd5e-4c0d-e064-9514188a07af"
   },
   "outputs": [],
   "source": [
    "df_count = data_pd.groupby('lesion_id').count()\n",
    "df_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ea9cd7",
   "metadata": {
    "id": "68ea9cd7"
   },
   "outputs": [],
   "source": [
    "df_count = df_count[df_count['dx'] == 1]\n",
    "df_count.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24cbd54",
   "metadata": {
    "id": "e24cbd54"
   },
   "outputs": [],
   "source": [
    "def duplicates(x):\n",
    "    unique = set(df_count['lesion_id'])\n",
    "    if x in unique:\n",
    "        return 'no' \n",
    "    else:\n",
    "        return 'duplicates'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25e9438",
   "metadata": {
    "id": "a25e9438",
    "outputId": "d996c234-31a1-48fd-acee-81561d2610c7"
   },
   "outputs": [],
   "source": [
    "data_pd['is_duplicate'] = data_pd['lesion_id'].apply(duplicates)\n",
    "data_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43cbc2f",
   "metadata": {
    "id": "c43cbc2f"
   },
   "outputs": [],
   "source": [
    "df_count = data_pd[data_pd['is_duplicate'] == 'no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418d8782",
   "metadata": {
    "id": "418d8782"
   },
   "outputs": [],
   "source": [
    "train, test_df = train_test_split(df_count, test_size=0.15, stratify=df_count['dx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae82a8b",
   "metadata": {
    "id": "0ae82a8b",
    "outputId": "61fbe8ea-ac4e-4688-c211-ecbe6a920119"
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ed1564",
   "metadata": {
    "id": "d2ed1564",
    "outputId": "5c7e2de4-6a04-4f03-baa2-6c91581bf959"
   },
   "outputs": [],
   "source": [
    "def identify_trainOrtest(x):\n",
    "    test_data = set(test_df['image_id'])\n",
    "    if str(x) in test_data:\n",
    "        return 'test'\n",
    "    else:\n",
    "        return 'train'\n",
    "\n",
    "#creating train_df\n",
    "data_pd['train_test_split'] = data_pd['image_id'].apply(identify_trainOrtest)\n",
    "train_df = data_pd[data_pd['train_test_split'] == 'train']\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3a2719",
   "metadata": {
    "id": "ce3a2719"
   },
   "outputs": [],
   "source": [
    "# Image id of train and test images\n",
    "train_list = list(train_df['image_id'])\n",
    "test_list = list(test_df['image_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f4035d",
   "metadata": {
    "id": "f7f4035d",
    "outputId": "4a3db2c8-9a53-4cbd-c1b8-cc440b071c57"
   },
   "outputs": [],
   "source": [
    "print(len(test_list))\n",
    "\n",
    "print(len(train_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b5467b",
   "metadata": {
    "id": "c7b5467b"
   },
   "source": [
    "# AUGMENTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c59c67e",
   "metadata": {
    "id": "1c59c67e"
   },
   "outputs": [],
   "source": [
    "data_pd.set_index('image_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7067156",
   "metadata": {
    "id": "f7067156"
   },
   "outputs": [],
   "source": [
    "os.mkdir(train_dir)\n",
    "os.mkdir(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8794170a",
   "metadata": {
    "id": "8794170a"
   },
   "outputs": [],
   "source": [
    "targetnames = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8144a9b3",
   "metadata": {
    "id": "8144a9b3"
   },
   "outputs": [],
   "source": [
    "for i in targetnames:\n",
    "    directory1=train_dir+'/'+i\n",
    "    directory2=test_dir+'/'+i\n",
    "    os.mkdir(directory1)\n",
    "    os.mkdir(directory2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0457d785",
   "metadata": {
    "id": "0457d785"
   },
   "outputs": [],
   "source": [
    "for image in train_list:\n",
    "    file_name = image+'.jpg'\n",
    "    label = data_pd.loc[image, 'dx']\n",
    "\n",
    "    # path of source image \n",
    "    source = os.path.join(r'C:\\Users\\divya\\Downloads\\archive\\ham', file_name)\n",
    "\n",
    "    # copying the image from the source to target file\n",
    "    target = os.path.join(train_dir, label, file_name)\n",
    "\n",
    "    shutil.copyfile(source, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea4ea7b",
   "metadata": {
    "id": "5ea4ea7b"
   },
   "outputs": [],
   "source": [
    "for image in test_list:\n",
    "\n",
    "    file_name = image+'.jpg'\n",
    "    label = data_pd.loc[image, 'dx']\n",
    "\n",
    "    # path of source image \n",
    "    source = os.path.join(r'C:\\Users\\divya\\Downloads\\archive\\ham', file_name)\n",
    "\n",
    "    # copying the image from the source to target file\n",
    "    target = os.path.join(test_dir, label, file_name)\n",
    "\n",
    "    shutil.copyfile(source, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5d45bd",
   "metadata": {
    "id": "4f5d45bd"
   },
   "outputs": [],
   "source": [
    "targetnames = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
    "\n",
    "# Augmenting images and storing them in temporary directories \n",
    "for img_class in targetnames:\n",
    "\n",
    "    #creating temporary directories\n",
    "    # creating a base directory\n",
    "    aug_dir = 'aug_dir'\n",
    "    os.mkdir(aug_dir)\n",
    "    # creating a subdirectory inside the base directory for images of the same class\n",
    "    img_dir = os.path.join(aug_dir, 'img_dir')\n",
    "    os.mkdir(img_dir)\n",
    "\n",
    "    img_list = os.listdir('HAM10000/train_dir/' + img_class)\n",
    "\n",
    "    # Copy images from the class train dir to the img_dir \n",
    "    for file_name in img_list:\n",
    "\n",
    "        # path of source image in training directory\n",
    "        source = os.path.join('HAM10000/train_dir/' + img_class, file_name)\n",
    "\n",
    "        # creating a target directory to send images \n",
    "        target = os.path.join(img_dir, file_name)\n",
    "\n",
    "        # copying the image from the source to target file\n",
    "        shutil.copyfile(source, target)\n",
    "\n",
    "    # Temporary augumented dataset directory.\n",
    "    source_path = aug_dir\n",
    "\n",
    "    # Augmented images will be saved to training directory\n",
    "    save_path = 'HAM10000/train_dir/' + img_class\n",
    "\n",
    "    # Creating Image Data Generator to augment images\n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "\n",
    "        rotation_range=180,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest'\n",
    "\n",
    "    )\n",
    "\n",
    "    batch_size = 50\n",
    "\n",
    "    aug_datagen = datagen.flow_from_directory(source_path,save_to_dir=save_path,save_format='jpg',target_size=(224, 224),batch_size=batch_size)\n",
    "\n",
    "    # Generate the augmented images\n",
    "    aug_images = 8000 \n",
    "\n",
    "    num_files = len(os.listdir(img_dir))\n",
    "    num_batches = int(np.ceil((aug_images - num_files) / batch_size))\n",
    "\n",
    "    # creating 8000 augmented images per class\n",
    "    for i in range(0, num_batches):\n",
    "        images, labels = next(aug_datagen)\n",
    "\n",
    "    # delete temporary directory \n",
    "    shutil.rmtree('aug_dir')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb1030b",
   "metadata": {
    "id": "7bb1030b"
   },
   "source": [
    "# TRAINING AND EXPERIMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4d2156",
   "metadata": {
    "id": "5a4d2156"
   },
   "outputs": [],
   "source": [
    "train_path = 'HAM10000/train_dir'\n",
    "test_path = 'HAM10000/test_dir'\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8608e2ac",
   "metadata": {
    "id": "8608e2ac"
   },
   "outputs": [],
   "source": [
    "datagen=ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e565bb5",
   "metadata": {
    "id": "1e565bb5",
    "outputId": "ea09200b-22b9-415f-9ff6-508dfb2783c5"
   },
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "print(\"\\nTrain Batches: \")\n",
    "train_batches = datagen.flow_from_directory(directory=train_path,\n",
    "                                            target_size=(image_size,image_size),\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True)\n",
    "\n",
    "print(\"\\nTest Batches: \")\n",
    "test_batches =datagen.flow_from_directory(test_path,\n",
    "                                           target_size=(image_size,image_size),\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27d24f0",
   "metadata": {
    "id": "d27d24f0"
   },
   "outputs": [],
   "source": [
    "class_weights = {   \n",
    "                    0: 1.0,  # akiec\n",
    "                    1: 1.0,  # bcc\n",
    "                    2: 1.0,  # bkl\n",
    "                    3: 1.0,  # df\n",
    "                    4: 5.0,  # mel\n",
    "                    5: 1.0,  # nv\n",
    "                    6: 1.0,  # vasc\n",
    "                }\n",
    "\n",
    "\n",
    "checkpoint=  ModelCheckpoint(filepath ='e_2+SA.hdf5',monitor='val_accuracy',save_best_only=True,save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e86447",
   "metadata": {
    "id": "94e86447"
   },
   "outputs": [],
   "source": [
    "en = tf.keras.applications.EfficientNetB4(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=(224,224,3),\n",
    "    pooling=None,\n",
    "\n",
    ")\n",
    "# Exclude the last 28 layers of the model.\n",
    "conv = en.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7b322a",
   "metadata": {
    "id": "8e7b322a"
   },
   "outputs": [],
   "source": [
    "output = Flatten()(conv)\n",
    "conv = Dropout(0.25)(conv)\n",
    "output = Dense(7, activation='softmax')(output)\n",
    "model = Model(inputs=en.input, outputs=output)\n",
    "opt1=tf.keras.optimizers.Adam(learning_rate=0.001,epsilon=0.1)\n",
    "model.compile(optimizer=opt1,\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4e9bcd",
   "metadata": {
    "id": "fb4e9bcd",
    "outputId": "c30e956b-de40-40e8-bc0f-fa06e71e8a6f"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2c31c4",
   "metadata": {
    "id": "2e2c31c4"
   },
   "outputs": [],
   "source": [
    "filepath = \"e_4a6.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy',steps_per_epoch=(len(train_df)/10), verbose=2, save_best_only=True, mode='max',save_weights_only=False)\n",
    "callbacks_list = [checkpoint]\n",
    "history=model.fit(train_batches,epochs=1000,steps_per_epoch=(len(train_df)/10),validation_data=test_batches,callbacks=callbacks_list,class_weight=class_weights,validation_steps=len(test_df)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d44853",
   "metadata": {
    "id": "d4d44853"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3829ce61",
   "metadata": {
    "id": "3829ce61"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "#LOAD EFFICIENTNETMODEL if already trained\n",
    "model.load_weights(\"e_4.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344331bb",
   "metadata": {
    "id": "344331bb"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_batches, steps=len(test_df)/batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bc581c",
   "metadata": {
    "id": "30bc581c",
    "outputId": "d613cc2a-ee27-49c5-d2bd-97ae78aad396",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#geting predictions on test dataset\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "targetnames = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
    "#getting the true labels per image \n",
    "y_true = test_batches.classes\n",
    "#getting the predicted labels per image \n",
    "y_prob=predictions\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_test = to_categorical(y_true)\n",
    "\n",
    "# Creating classification report \n",
    "report = classification_report(y_true, y_pred, target_names=targetnames,digits=4)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a29262",
   "metadata": {
    "id": "72a29262",
    "outputId": "a768b750-9d14-4598-d378-5bd1af43daef"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "report =accuracy_score(y_true, y_pred)\n",
    "\n",
    "print(\"\\nAccuracy:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edb806a",
   "metadata": {
    "id": "6edb806a",
    "outputId": "029f2b58-a939-46c7-88e9-a3283c731f00"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt     \n",
    "cm=confusion_matrix(y_true,y_pred)\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix of EfficientNet'); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ae1db2",
   "metadata": {
    "id": "53ae1db2",
    "outputId": "6b364998-357b-44d9-91d2-3222e314c809"
   },
   "outputs": [],
   "source": [
    "print(\"Precision: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\n",
    "print(\"weighted Roc score: \" + str(roc_auc_score(y_test,y_prob,multi_class='ovr',average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de6d863",
   "metadata": {
    "id": "3de6d863",
    "outputId": "04728aa6-27d0-45cd-b837-9502efdc1d31"
   },
   "outputs": [],
   "source": [
    "print(\"Precision: \"+ str(precision_score(y_true, y_pred, average='macro')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='macro')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\n",
    "print(\"Macro Roc score: \" + str(roc_auc_score(y_test,y_prob,multi_class='ovr',average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe27f604",
   "metadata": {
    "id": "fe27f604",
    "outputId": "575e964c-4176-4ba1-ef8e-379c0b309dcd"
   },
   "outputs": [],
   "source": [
    "print(\"Precision: \"+ str(precision_score(y_true, y_pred, average='micro')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='micro')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\n",
    "tpr={}\n",
    "fpr={}\n",
    "roc_auc={}\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_prob.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "print(\"Micro Roc score: \" + str(roc_auc[\"micro\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6b2ade",
   "metadata": {
    "id": "5f6b2ade",
    "outputId": "5a5c3c72-6ca5-402b-9bbf-524ead0c6f79"
   },
   "outputs": [],
   "source": [
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "avg=0\n",
    "for i in range(7):\n",
    "    r = roc_auc_score(y_test[:, i], y_prob[:, i])\n",
    "    avg+=r\n",
    "    print(\"The ROC AUC score of \"+targetnames[i]+\" is: \"+str(r))\n",
    "print(\"The Average ROC AUC score is\",avg/7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f961e7c1",
   "metadata": {
    "id": "f961e7c1"
   },
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = dict()\n",
    "for i in range(7):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_prob[:, i], drop_intermediate=False)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999502a6",
   "metadata": {
    "id": "999502a6",
    "outputId": "a49bd4d5-d358-4887-f946-97013388e7d9"
   },
   "outputs": [],
   "source": [
    "plt.plot(fpr[0], tpr[0],'v-',label='akiec: ROC curve of (area = %0.2f)' % roc_auc[0])\n",
    "plt.plot(fpr[1], tpr[1],'c',label='bcc: ROC curve of (area = %0.2f)' % roc_auc[1])\n",
    "plt.plot(fpr[2], tpr[2],'b',label='bkl: ROC curve of (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot(fpr[3], tpr[3],'g',label='df: ROC curve of (area = %0.2f)' % roc_auc[3])\n",
    "plt.plot(fpr[4], tpr[4],'y',label='mel: ROC curve of (area = %0.2f)' % roc_auc[4])\n",
    "plt.plot(fpr[5], tpr[5],'o-',label='nv: ROC curve of (area = %0.2f)' % roc_auc[5])\n",
    "plt.plot(fpr[6], tpr[6],'r',label='vasc: ROC curve of (area = %0.2f)' % roc_auc[6])\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([-0.1, 1.1])\n",
    "plt.ylim([-0.1, 1.1])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic of %s'%targetnames[i])\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e018d295",
   "metadata": {
    "id": "e018d295"
   },
   "outputs": [],
   "source": [
    "x_test,y_test=next(test_batches)\n",
    "x_test=np.asarray(x_test,dtype='int')\n",
    "sa_model = Model(model.inputs,model.get_layer('soft_attention').output)\n",
    "sa_features, sa_maps = sa_model.predict(tf.keras.applications.efficientnet.preprocess_input(x_test))\n",
    "\n",
    "sa_maps.shape\n",
    "img_idx = 0\n",
    "t = x_test # bring the range between 0,1 from -1,1\n",
    "plt.imshow(t[img_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8677d45",
   "metadata": {
    "id": "c8677d45"
   },
   "outputs": [],
   "source": [
    "sum_attnmap = np.sum(sa_maps[img_idx],0)\n",
    "sum_attnmap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cdfe08",
   "metadata": {
    "id": "30cdfe08"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "plt.imshow(t[img_idx],alpha=1.0)\n",
    "plt.imshow(cv2.resize(sum_attnmap,(224,224),interpolation=cv2.INTER_CUBIC),cmap='jet',alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdfaf0c",
   "metadata": {
    "id": "efdfaf0c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2c8849",
   "metadata": {
    "id": "5f2c8849"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
